![GitHub Logo](https://s3.ap-south-1.amazonaws.com/greyatom-social/GreyAtom-logo.png)

# Introduction to Machine Learning

## Lets Get Rolling - Student Pre-Read
Before this lesson , we recommend you to go through

 * Read through the [scikit-learn quick-start](http://scikit-learn.org/dev/tutorial/basic/tutorial.html).
 * Take a peak at the [Machine Learning Cheat Sheet (for scikit-learn)](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)


## Learning Objectives 

After this lesson, you'll be able to 

* Understand broad categories of Machine Learning Algorithms
* Understand the Machine Learning Workflow
* Work with Data 


## Agenda

* Merits of 3 Pass System
* What is Machine Learning?
* [History of Machine Learning](https://en.wikipedia.org/wiki/Timeline_of_machine_learning)
* Types of Machine Learning
* The Machine Learning Workflow

* Scientific Evolution 01 
    * Difference between Principal & Law
    * [Newton came up with a Principal](https://en.wikipedia.org/wiki/Philosophi%C3%A6_Naturalis_Principia_Mathematica)  
    * [J. D. Murray](http://www.springer.com/in/book/9780387952239)
    * Statisticians
    * Modern Data Science
* Management Evolution 02
    * Henry Ford - Personal Charisma - Key Lieutenants 
    * Toyota - Process - 6 Sigma
    * Michael Porter - 5 Forces - Consulting Practices 
    * Evolution of Decision Support Systems - Investment Banking 
    * Thomas Davenport - Analytics 3.0
    * Tactical Support - Mass Personalization
* Algorithmic Evolution
    * Originally prosposed in 1963 - SVM - [Vapnik](https://en.wikipedia.org/wiki/Support_vector_machine)
    * Kernel Mathematically implemented in 1995
    * SVM first won on Kaggle in [2013](https://jvns.ca/blog/2014/06/19/machine-learning-isnt-kaggle-competitions/) 
    * [History of Machine Learning](https://en.wikipedia.org/wiki/Timeline_of_machine_learning)

* Overview of key Algorithms
  #### [Deep Learning & Neural Nets](https://docs.google.com/spreadsheets/d/1fR4duGwU05o-STngjAaDIsHSxruiKOipfmTTX8NQtgY/pubhtml)
   * 1.1 No. of Layers
   * 1.2 No. of Nodes
   * 1.3 Weights
   * 1.4 Activation Function
   * 1.5 Learning Rate - Algorithms to vary Learning Rates
   * 1.6 Other Hyper Parameters
  #### [Ordinary Least Square](http://students.brown.edu/seeing-theory/regression/index.html#first)
   * 2.1 Regularization
   * 2.2 Shrinkage
   * 2.3 Kernels
  #### [Decision Tree - Entropy based](https://www.quora.com/What-is-an-intuitive-explanation-of-a-decision-tree) + [Marketing Example](http://www.simafore.com/blog/bid/78307/How-to-use-decision-trees-in-customer-acquisition-strategies)
   * 3.1 Tree Depth
   * 3.2 Prune
   * 3.3 Stopping Criteria
  #### [Maximum Likelihood](https://www.quora.com/How-do-you-explain-maximum-likelihood-estimation-intuitively) - [Video1](https://www.youtube.com/watch?v=I_dhPETvll8) + [Video2](https://www.youtube.com/watch?v=Z582V53dfr8) + [Video3](https://www.youtube.com/watch?v=jpHreXjtw1Q)
   * 4.1 This is a Base Algorithm  
  #### [PCA](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)
   * 5.1 No. of Components
   * 5.2 Learning Rate
   * 5.3 Random Seed
  #### [Stochastic Gradient Descent](https://www.quora.com/What-is-an-intuitive-explanation-of-gradient-descent) 
   * 6.1 Learning rate 
   * 6.2 Type of Loss Function
   * 6.3 Penalty
  #### [Clustering - Centroid Based](https://www.slideshare.net/kasunrangawijeweera/k-means-clustering-algorithm)
   * 7.1 No. of clusters 
   * 7.2 Algorithm - 
   * 7.3 N Jobs - Random Seed
  #### [Ensembles](https://www.youtube.com/watch?v=Cn7StaXU_8o)
   * 8.1 Everything in Oridinary Least Square/ Decision Tree and Stochastic Gradient Descent more

* Thinking about Data
* Where does Data Come from?
* How to Access Data?
  * Data from the Web 1 (Web Scraping)
  * Data from the Web 2 (APIs)


## Slides

@[gslides](1mvRfxXCs1Oha9njg87LOgvgE9hDNkgsfra3PdIbzVA4)

## Instructors code alongs

* [Thinking about Data](https://github.com/commit-live-students/Intro-to-machine-learning/blob/master/002_week_1_day_1.ipynb)
* [Introduction to Machine Learning](https://github.com/commit-live-students/Intro-to-machine-learning/blob/master/001_intro_to_ml.ipynb)


## Assignments 
[Complete this  setup before attempting the assignments](https://github.com/commit-live-students/Intro-to-machine-learning/blob/master/00_preclass/000_pre-class-activities.ipynb)


& many more inside commit.live.


## Resources & Post Reads

* Check out the [intro to scikit-learn][] video series from SciPy2013.
* Learn more about `sklearn` by reading [API design for machine learning software: experiences from the scikit-learn project](http://arxiv.org/abs/1309.0238).
 * Check out [Datalicious Notebookmania â€“ My favorite 7 IPython Notebooks](http://beautifuldata.net/2014/03/datalicious-notebookmania-my-favorite-7-ipython-notebooks/)
* [intro to scikit-learn]: https://www.youtube.com/watch?v=r4bRUvvlaBw
* Find out more about [Nicholas Nassim Taleb](https://en.wikipedia.org/wiki/Nassim_Nicholas_Taleb)
* He has written following landmark books:
  * Fooled by Randomness
  * The Black Swan
  * Anti Fragile 
  * Feedly 
  * Curate your personal feed for ML and DS

 * Feedly
    * [Algorithmia](http://blog.algorithmia.com/rss)
    * [Algorithms for the Masses - Julian m Bucknall](http://feeds.feedburner.com/boyet/blog)
    * [Algorithms Weekly by Petr Mitrichev](http://petr-mitrichev.blogspot.com/feeds/posts/default)
    * [Artificial Intelligence News -- ScienceDaily](http://www.sciencedaily.com/rss/computers_math/artificial_intelligence.xml)
    * [Daniel Lemire's blog](http://feeds.feedburner.com/daniel-lemire/atom)
    * [Data Science 101](http://datascience101.wordpress.com/feed/)
    * [DataTau](http://www.datatau.com/rss)
    * [Everyone's Blog Posts](http://www.datasciencecentral.com/profiles/blog/feed?xn_auth=no)
    * [FastML](http://fastml.com/atom.xml)
    * [Geeking with Greg](http://glinden.blogspot.com/feeds/posts/defa)
    * [GeeksforGeeks](http://feeds.feedburner.com/Geeksforgeeks)
    * [Journal of Machine Learning Research](http://jmlr.csail.mit.edu/jmlr.xml)
    * [KDnuggets](http://feeds.feedburner.com/kdnuggets-data-mining-analytics)
    * [Machine Learning](http://www.reddit.com/r/MachineLearning/.rss)
    * [Machine Learning (Theory)](http://hunch.net/?feed=rss2)
    * [Machine Learning Mastery](http://feeds.feedburner.com/MachineLearningMastery)
    * [Neural Networks](http://rss.sciencedirect.com/publication/science/08936080)
    * [Newest questions tagged scikit-learn - Stack Overflow](http://stackoverflow.com/feeds/tag?tagnames=scikit-learn&sort=newest)
    * [No Free Hunch](http://blog.kaggle.com/feed/)
    * [Nuit Blanche](http://nuit-blanche.blogspot.com/feeds/posts/default)
    * [Simply Statistics](http://simplystatistics.org/feed/)
    * [Statistical Modeling, Causal Inference, and Social Science](http://www.stat.columbia.edu/~cook/movabletype/mlm/atom.xml)
    * [mathbabe](http://mathbabe.org/feed/)
 * Curate your personal feed for ML and DS
 * Add the relevant channels on Youtube 
    * [Abu Yaser Mostafa](https://www.youtube.com/playlist?list=PLD63A284B7615313A)
    * [Victor Lavrenko](https://www.youtube.com/user/victorlavrenko/featured)
    * [Nat & Friends](https://www.youtube.com/playlist?list=PLeqAcoTy5743VbzOnh78inJMEpl1IRyLL)
    * [Hugo Larochelle](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)
    * [Ben Lambert](https://www.youtube.com/channel/UC3tFZR3eL1bDY8CqZDOQh-w)
    * [Mathematical Monk](https://www.youtube.com/channel/UCcAtD_VYwcYwVbTdvArsm7w)

   * **Answer Questions**:

  * Can search based algorithms be applied for Linear Regression?
  * Create an Excel sheet 
    * Can you build a regression model in MS Excel? [Solution](http://www.clemson.edu/ces/phoenix/tutorials/excel/regression.html)
    * Can you build a regression model in MS Excel using closed form equations?
    * Can you build a regression model in MS Excel using SGD?

